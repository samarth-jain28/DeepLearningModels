{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b6a38c-499b-4e88-a86b-e00216346a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291dcfb9-3a77-4a84-a6fe-f369823df13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/Users/normous/Desktop/RoadToHeaven/springboard/datasets/FashionItemRecognisation/fashionmnisttrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c8c7b39-34d3-4476-a1a7-34a155d65f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = np.asarray(train_data.iloc[1:2, 1:]).reshape(28,28)\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93af53b4-12fa-4991-8e56-c26f5b022b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x130469970>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1, cmap = plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab893a9-3944-4c44-ab97-125024ce1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = train_data.iloc[:5000,:]\n",
    "\n",
    "val_label = val_data.label\n",
    "train_label = train_data.label\n",
    "\n",
    "train_images = train_data.iloc[:, 1:].values.reshape(60000, 28, 28)\n",
    "val_images = val_data.iloc[:, 1:].values.reshape(5000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a650ddc-0a1f-4f7f-bec6-cb4f6fa4cdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/normous/Desktop/RoadToHeaven/udemyPythonDSA/.venv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0797 - loss: 7.6479 - val_accuracy: 0.1350 - val_loss: 5.9564\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1553 - loss: 5.5097 - val_accuracy: 0.1788 - val_loss: 3.6047\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1509 - loss: 7.9237 - val_accuracy: 0.2434 - val_loss: 3.4471\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2044 - loss: 3.3703 - val_accuracy: 0.1870 - val_loss: 3.4625\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1955 - loss: 3.3848 - val_accuracy: 0.1936 - val_loss: 3.4238\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(1, activation = tf.keras.activations.linear),\n",
    "    keras.layers.Dense(10, activation = tf.keras.activations.linear)\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = keras.optimizers.Adam(),\n",
    "             metrics = ['accuracy'])\n",
    "model1 = model.fit(train_images, train_label, epochs = 5, validation_data = (val_images, val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576b10b0-87ef-42b2-ae0f-e375cc4252c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1240 - loss: 6.7296 - val_accuracy: 0.1256 - val_loss: 2.3118\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1297 - loss: 2.3075 - val_accuracy: 0.1256 - val_loss: 2.3118\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1308 - loss: 2.3068 - val_accuracy: 0.1256 - val_loss: 2.3118\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1293 - loss: 2.3120 - val_accuracy: 0.1256 - val_loss: 2.3118\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1306 - loss: 2.3093 - val_accuracy: 0.1256 - val_loss: 2.3118\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(10, activation = tf.keras.activations.linear),\n",
    "    keras.layers.Dense(10, activation = tf.keras.activations.linear)\n",
    "])\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model2 = model.fit(train_images, train_label, epochs = 5, validation_data = (val_images, val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "785f6e26-7a3f-4aee-abc4-562af82c67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1023 - loss: 4.7048 - val_accuracy: 0.1138 - val_loss: 2.2731\n",
      "Epoch 2/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1176 - loss: 2.2711 - val_accuracy: 0.1188 - val_loss: 2.2488\n",
      "Epoch 3/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1255 - loss: 2.2544 - val_accuracy: 0.1358 - val_loss: 2.2227\n",
      "Epoch 4/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1321 - loss: 2.2400 - val_accuracy: 0.1410 - val_loss: 2.2000\n",
      "Epoch 5/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1393 - loss: 2.2135 - val_accuracy: 0.1414 - val_loss: 2.1964\n",
      "Epoch 6/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1543 - loss: 2.1823 - val_accuracy: 0.1764 - val_loss: 2.1205\n",
      "Epoch 7/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1977 - loss: 2.0293 - val_accuracy: 0.2350 - val_loss: 1.8049\n",
      "Epoch 8/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2362 - loss: 1.8024 - val_accuracy: 0.2734 - val_loss: 1.7580\n",
      "Epoch 9/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2512 - loss: 1.7401 - val_accuracy: 0.2822 - val_loss: 1.6984\n",
      "Epoch 10/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2641 - loss: 1.7097 - val_accuracy: 0.2768 - val_loss: 1.7010\n",
      "Epoch 11/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2770 - loss: 1.6749 - val_accuracy: 0.3032 - val_loss: 1.6469\n",
      "Epoch 12/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2902 - loss: 1.6597 - val_accuracy: 0.3072 - val_loss: 1.6754\n",
      "Epoch 13/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3032 - loss: 1.6403 - val_accuracy: 0.3278 - val_loss: 1.5992\n",
      "Epoch 14/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3236 - loss: 1.6090 - val_accuracy: 0.3384 - val_loss: 1.5803\n",
      "Epoch 15/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3365 - loss: 1.5784 - val_accuracy: 0.3442 - val_loss: 1.5521\n",
      "Epoch 16/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3416 - loss: 1.5646 - val_accuracy: 0.3590 - val_loss: 1.5290\n",
      "Epoch 17/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3467 - loss: 1.5391 - val_accuracy: 0.3660 - val_loss: 1.5004\n",
      "Epoch 18/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3525 - loss: 1.5257 - val_accuracy: 0.3648 - val_loss: 1.5035\n",
      "Epoch 19/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3544 - loss: 1.5361 - val_accuracy: 0.3408 - val_loss: 1.5115\n",
      "Epoch 20/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3599 - loss: 1.5141 - val_accuracy: 0.3874 - val_loss: 1.4504\n",
      "Epoch 21/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3803 - loss: 1.4786 - val_accuracy: 0.3738 - val_loss: 1.4814\n",
      "Epoch 22/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3892 - loss: 1.4595 - val_accuracy: 0.3818 - val_loss: 1.4589\n",
      "Epoch 23/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3963 - loss: 1.4247 - val_accuracy: 0.4238 - val_loss: 1.4156\n",
      "Epoch 24/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4153 - loss: 1.3948 - val_accuracy: 0.4376 - val_loss: 1.3786\n",
      "Epoch 25/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4299 - loss: 1.3574 - val_accuracy: 0.4390 - val_loss: 1.4306\n",
      "Epoch 26/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4369 - loss: 1.3255 - val_accuracy: 0.4388 - val_loss: 1.3445\n",
      "Epoch 27/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4430 - loss: 1.2967 - val_accuracy: 0.4362 - val_loss: 1.3053\n",
      "Epoch 28/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4409 - loss: 1.3032 - val_accuracy: 0.4506 - val_loss: 1.3558\n",
      "Epoch 29/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4388 - loss: 1.3122 - val_accuracy: 0.4344 - val_loss: 1.3312\n",
      "Epoch 30/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4458 - loss: 1.2940 - val_accuracy: 0.3290 - val_loss: 1.6304\n",
      "Epoch 31/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4305 - loss: 1.3336 - val_accuracy: 0.4438 - val_loss: 1.2770\n",
      "Epoch 32/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4472 - loss: 1.2993 - val_accuracy: 0.4518 - val_loss: 1.2726\n",
      "Epoch 33/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4516 - loss: 1.2741 - val_accuracy: 0.4168 - val_loss: 1.3749\n",
      "Epoch 34/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4439 - loss: 1.3017 - val_accuracy: 0.4556 - val_loss: 1.2542\n",
      "Epoch 35/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4417 - loss: 1.3104 - val_accuracy: 0.4524 - val_loss: 1.2690\n",
      "Epoch 36/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.4466 - loss: 1.2678 - val_accuracy: 0.4566 - val_loss: 1.2497\n",
      "Epoch 37/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.4517 - loss: 1.2632 - val_accuracy: 0.4560 - val_loss: 1.2473\n",
      "Epoch 38/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4558 - loss: 1.2633 - val_accuracy: 0.4462 - val_loss: 1.2618\n",
      "Epoch 39/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4483 - loss: 1.2639 - val_accuracy: 0.4584 - val_loss: 1.2518\n",
      "Epoch 40/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4545 - loss: 1.2699 - val_accuracy: 0.4198 - val_loss: 1.3618\n",
      "Epoch 41/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4465 - loss: 1.2840 - val_accuracy: 0.4600 - val_loss: 1.2296\n",
      "Epoch 42/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4556 - loss: 1.2600 - val_accuracy: 0.4438 - val_loss: 1.2893\n",
      "Epoch 43/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4539 - loss: 1.2772 - val_accuracy: 0.4472 - val_loss: 1.2596\n",
      "Epoch 44/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4514 - loss: 1.2683 - val_accuracy: 0.4592 - val_loss: 1.2363\n",
      "Epoch 45/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4487 - loss: 1.2692 - val_accuracy: 0.4608 - val_loss: 1.2424\n",
      "Epoch 46/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4544 - loss: 1.2805 - val_accuracy: 0.4566 - val_loss: 1.2671\n",
      "Epoch 47/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4657 - loss: 1.2603 - val_accuracy: 0.4674 - val_loss: 1.2471\n",
      "Epoch 48/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4794 - loss: 1.2287 - val_accuracy: 0.4408 - val_loss: 1.2925\n",
      "Epoch 49/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4673 - loss: 1.2714 - val_accuracy: 0.4962 - val_loss: 1.2249\n",
      "Epoch 50/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4872 - loss: 1.2203 - val_accuracy: 0.4970 - val_loss: 1.2099\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(10, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model3 = model.fit(train_images, train_label, epochs = 50, validation_data = (val_images, val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711cd1b1-fc9d-4499-80bc-98540dc94eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/normous/Desktop/RoadToHeaven/udemyPythonDSA/.venv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.2715 - loss: 3.4111 - val_accuracy: 0.4446 - val_loss: 1.3427\n",
      "Epoch 2/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4700 - loss: 1.2709 - val_accuracy: 0.5084 - val_loss: 1.1419\n",
      "Epoch 3/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 1.1163 - val_accuracy: 0.5758 - val_loss: 1.0352\n",
      "Epoch 4/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 1.0227 - val_accuracy: 0.6108 - val_loss: 0.9441\n",
      "Epoch 5/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.9568 - val_accuracy: 0.6570 - val_loss: 0.8922\n",
      "Epoch 6/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.8754 - val_accuracy: 0.6966 - val_loss: 0.7686\n",
      "Epoch 7/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.7876 - val_accuracy: 0.7346 - val_loss: 0.7095\n",
      "Epoch 8/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.7344 - val_accuracy: 0.7348 - val_loss: 0.7089\n",
      "Epoch 9/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.7046 - val_accuracy: 0.7396 - val_loss: 0.6723\n",
      "Epoch 10/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.6854 - val_accuracy: 0.7412 - val_loss: 0.6957\n",
      "Epoch 11/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7420 - loss: 0.6723 - val_accuracy: 0.7548 - val_loss: 0.6403\n",
      "Epoch 12/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.6607 - val_accuracy: 0.7576 - val_loss: 0.6520\n",
      "Epoch 13/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.6450 - val_accuracy: 0.7688 - val_loss: 0.6266\n",
      "Epoch 14/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.6475 - val_accuracy: 0.7530 - val_loss: 0.6912\n",
      "Epoch 15/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7668 - loss: 0.6299 - val_accuracy: 0.7724 - val_loss: 0.6246\n",
      "Epoch 16/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.6253 - val_accuracy: 0.7758 - val_loss: 0.6093\n",
      "Epoch 17/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.6204 - val_accuracy: 0.7800 - val_loss: 0.6184\n",
      "Epoch 18/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.6106 - val_accuracy: 0.7952 - val_loss: 0.5756\n",
      "Epoch 19/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.5998 - val_accuracy: 0.7848 - val_loss: 0.5949\n",
      "Epoch 20/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7789 - loss: 0.6078 - val_accuracy: 0.7942 - val_loss: 0.5822\n",
      "Epoch 21/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.5999 - val_accuracy: 0.8014 - val_loss: 0.5584\n",
      "Epoch 22/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7856 - loss: 0.5931 - val_accuracy: 0.7914 - val_loss: 0.5806\n",
      "Epoch 23/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.5895 - val_accuracy: 0.8020 - val_loss: 0.5692\n",
      "Epoch 24/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7880 - loss: 0.5836 - val_accuracy: 0.7874 - val_loss: 0.5824\n",
      "Epoch 25/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7875 - loss: 0.5919 - val_accuracy: 0.7920 - val_loss: 0.5853\n",
      "Epoch 26/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.5892 - val_accuracy: 0.7982 - val_loss: 0.5600\n",
      "Epoch 27/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7901 - loss: 0.5774 - val_accuracy: 0.7902 - val_loss: 0.6049\n",
      "Epoch 28/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.5780 - val_accuracy: 0.8052 - val_loss: 0.5360\n",
      "Epoch 29/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5765 - val_accuracy: 0.8004 - val_loss: 0.5651\n",
      "Epoch 30/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7892 - loss: 0.5751 - val_accuracy: 0.8030 - val_loss: 0.5605\n",
      "Epoch 31/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7906 - loss: 0.5706 - val_accuracy: 0.8024 - val_loss: 0.5399\n",
      "Epoch 32/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7888 - loss: 0.5780 - val_accuracy: 0.7960 - val_loss: 0.5772\n",
      "Epoch 33/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.5721 - val_accuracy: 0.8070 - val_loss: 0.5384\n",
      "Epoch 34/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7921 - loss: 0.5712 - val_accuracy: 0.7974 - val_loss: 0.5526\n",
      "Epoch 35/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.5701 - val_accuracy: 0.7998 - val_loss: 0.5507\n",
      "Epoch 36/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.5735 - val_accuracy: 0.7966 - val_loss: 0.5788\n",
      "Epoch 37/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.5654 - val_accuracy: 0.7946 - val_loss: 0.5775\n",
      "Epoch 38/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7961 - loss: 0.5642 - val_accuracy: 0.8038 - val_loss: 0.5446\n",
      "Epoch 39/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.5632 - val_accuracy: 0.7994 - val_loss: 0.5650\n",
      "Epoch 40/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.5592 - val_accuracy: 0.8060 - val_loss: 0.5401\n",
      "Epoch 41/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.5594 - val_accuracy: 0.8020 - val_loss: 0.5559\n",
      "Epoch 42/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.5546 - val_accuracy: 0.8058 - val_loss: 0.5350\n",
      "Epoch 43/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7984 - loss: 0.5567 - val_accuracy: 0.7600 - val_loss: 0.6555\n",
      "Epoch 44/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.5687 - val_accuracy: 0.8082 - val_loss: 0.5471\n",
      "Epoch 45/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7958 - loss: 0.5677 - val_accuracy: 0.8084 - val_loss: 0.5432\n",
      "Epoch 46/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7946 - loss: 0.5598 - val_accuracy: 0.8020 - val_loss: 0.5486\n",
      "Epoch 47/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7973 - loss: 0.5569 - val_accuracy: 0.8074 - val_loss: 0.5383\n",
      "Epoch 48/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.5614 - val_accuracy: 0.7860 - val_loss: 0.5909\n",
      "Epoch 49/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7975 - loss: 0.5644 - val_accuracy: 0.8022 - val_loss: 0.5444\n",
      "Epoch 50/50\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7963 - loss: 0.5595 - val_accuracy: 0.8088 - val_loss: 0.5461\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(10, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = (['accuracy'])\n",
    ")\n",
    "model4 = model.fit(train_images, train_label, epochs = 50, validation_data = (val_images, val_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
